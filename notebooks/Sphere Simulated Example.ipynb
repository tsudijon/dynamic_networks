{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulated Example 2\n",
    "We should consider an example where the underlying graph structure also changes. Perhaps we could have an example: consider temperature on the earth as a function $T:[0,a] \\rightarrow \\mathbb{S}^2 \\times \\mathbb{R}.$ Suppose that the temperature is a periodic function, and it is observed around the world at random spots everyday. Hence, at each time, we get a network whose topology approximates that of the sphere. Its points have values determined by the function $T,$ and the edges could represent physical distance. Hence, we have a function that is sampled from a different set of locations at each time, giving rise to a dynamic network where the graph structure changes.\n",
    "\n",
    "We define a set of sites, a collection of $N$ points on the sphere from which $T$ can be observed. However, the set of sites changes with time - on some measurement periods, only some sites will record data, and some sites will be added / drop out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating graphs on spheres\n",
    "create graphs on spheres. Go from a collection of points on the sphere to a network. Connect points that are closest to each other - does this give a planar embedding. No.\n",
    "\n",
    "We instead sample a collection of poitns on the sphere, and compute its delaunay triangulation, which gives a triangulation of this graph on the sphere. We can compute this easily by taking the convex hull on the sphere. We can also fill in the (geodesic) distance between two points using the haversine formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial as sp\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def sample_uniform_sphere(N):\n",
    "    cds = np.random.normal(0,1,(N,3))\n",
    "    normalized_cds = cds/np.reshape(np.sqrt(np.sum(cds**2,axis = 1)),(N,1))\n",
    "    return normalized_cds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify that points are on sphere\n",
    "points = sample_uniform_sphere(100)\n",
    "fig = plt.figure(figsize = (5,5))\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "ax.scatter(points[:,0],points[:,1],points[:,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the convex hull\n",
    "hull = sp.ConvexHull(points)\n",
    "\n",
    "fig = plt.figure(figsize = (5,5))\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "for simplex in hull.simplices:\n",
    "     ax.plot(points[simplex, 0], points[simplex, 1], points[simplex, 2], 'k-')\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the adjacency graph of this triangulation\n",
    "import itertools as itr\n",
    "\n",
    "def simplex_list_to_adjacency_graph(simplex_list):\n",
    "    pass\n",
    "\n",
    "# simplex_list is an array of arrays\n",
    "def simplex_list_to_edge_list(simplex_list):\n",
    "    edges = set()\n",
    "    for simplex in simplex_list:\n",
    "        simp_edges = set(itr.combinations(simplex,2)) \n",
    "        edges = edges.union(simp_edges)\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cds should be an array of size (3,)\n",
    "def cartesian_to_spherical(cds):\n",
    "    (x,y,z) = cds\n",
    "    rho = np.sqrt(np.sum(cds**2))\n",
    "    r = np.sqrt(x**2 + y**2)\n",
    "    theta = np.arccos(x/r)\n",
    "    phi = np.arcsin(r/rho)\n",
    "    \n",
    "    return (rho,phi,theta)\n",
    "\n",
    "def cartesian_to_sphere_distance(cds1,cds2):\n",
    "    (rho,lat1,lon1) = cartesian_to_spherical(cds1)\n",
    "    (rho,lat2,lon2) = cartesian_to_spherical(cds2)\n",
    "    \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    \n",
    "    a = np.sqrt(np.sin(dlat/2)**2 + np.cos(lat2)*np.cos(lat1)*np.sin(dlon/2)**2)\n",
    "    c = np.arcsin(a)\n",
    "    \n",
    "    return 2*rho*c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node weights are sampled from a periodic function on the sphere. sin(t + 2*pi*z)?\n",
    "def periodic_northsouth_modulated(t,cds, T):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    t: float\n",
    "        Time index\n",
    "    cds: ndarray(N, 3)\n",
    "        Cartesion coordinates of sphere points\n",
    "    T: float\n",
    "        Period of a cycle\n",
    "    \"\"\"\n",
    "    rho, phi, theta = cartesian_to_spherical(cds)\n",
    "    return 3 + 2*np.cos(2*np.pi*t/T + 2*phi)\n",
    "\n",
    "def sph_harm_modulated(t,cds, T, m, n):\n",
    "    \"\"\"\n",
    "    A modulated spherical harmonic\n",
    "    Parameters\n",
    "    ----------\n",
    "    t: float\n",
    "        Time index\n",
    "    cds: ndarray(N, 3)\n",
    "        Cartesion coordinates of sphere points\n",
    "    T: float\n",
    "        Period of a cycle\n",
    "    m: int\n",
    "        m parameter for spherical harmonics\n",
    "    n: int\n",
    "        n parameter for spherical harmonics\n",
    "    \"\"\"\n",
    "    from scipy.special import sph_harm\n",
    "    rho, phi, theta = cartesian_to_spherical(cds)\n",
    "    return np.sin(2*np.pi*t/T)*np.real(sph_harm(n, m, theta, phi))\n",
    "\n",
    "def get_node_wts(t,hull_obj, obsfn):\n",
    "    hull = hull_obj\n",
    "    node_wts = [obsfn(t,p) for p in hull.points]\n",
    "    return np.array(node_wts)\n",
    "    \n",
    "def get_edge_wts(hull_obj, alpha = 1.0):\n",
    "    \"\"\"\n",
    "    map edges to their distances\n",
    "    use this to create a dynamic network, edges are these distances.\n",
    "    Returns\n",
    "    -------\n",
    "    edges: scipy.sparse(N, N)\n",
    "        A sparse matrix with the edge weights\n",
    "    alpha: float\n",
    "        Amount by which to weight distances\n",
    "    \"\"\"\n",
    "    hull = hull_obj\n",
    "    edges = simplex_list_to_edge_list(hull.simplices)\n",
    "    \n",
    "    v = hull.points\n",
    "    ds = [cartesian_to_sphere_distance(v[e[0],:], v[e[1],:]) for e in edges]\n",
    "    ds = alpha*np.array(ds + ds)\n",
    "    \n",
    "    e0 = np.array([e[0] for e in edges] + [e[1] for e in edges])\n",
    "    e1 = np.array([e[1] for e in edges] + [e[0] for e in edges])\n",
    "    \n",
    "    return sparse.coo_matrix((ds, (e0, e1)), shape=(len(v), len(v)))\n",
    "  \n",
    "def create_dynamic_network(time_indices, obsfn, edge_wtsfn, change_param = 3, seed = 0):\n",
    "    \"\"\"\n",
    "    Create a sphere network where points are deleted and added at each step\n",
    "    Parameters\n",
    "    ----------\n",
    "    time_indices: ndarray(M)\n",
    "        Times at which to sample the observation function\n",
    "    obsfn: function: (t, ndarray(N, 3)) -> ndarray(N)\n",
    "        An observation function for points on the sphere\n",
    "    change_param: int\n",
    "        The maximum number of points to add or delete at each \n",
    "        point in time\n",
    "    seed: int\n",
    "        Random seed for repeatable results\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    node_wts = []\n",
    "    edge_wts = []\n",
    "    \n",
    "    # generate random set of points initially\n",
    "    points = sample_uniform_sphere(100)\n",
    "    allpoints = []\n",
    "    \n",
    "    # create networks for each time step\n",
    "    total_removed = 0\n",
    "    for t in time_indices:\n",
    "        \n",
    "        # replace a random set of the points\n",
    "        num_del = np.random.randint(change_param+1)\n",
    "        num_ins = np.random.randint(change_param+1)\n",
    "        total_removed += num_del\n",
    "        points = update_points(points, num_del, num_ins)\n",
    "        \n",
    "        hull = sp.ConvexHull(points)\n",
    "        node_wts.append(get_node_wts(t,hull, obsfn))\n",
    "        edge_wts.append(edge_wtsfn(hull))\n",
    "        allpoints.append(points)\n",
    "    print(\"Total Removed: %i\"%total_removed)\n",
    "    return (node_wts,edge_wts,allpoints)\n",
    "\n",
    "def update_points(pt_list,num_del,num_ins):\n",
    "    if len(pt_list) + num_ins - num_del <= 0:\n",
    "        raise Exception('result has non positive length')\n",
    "    \n",
    "    new_points = sample_uniform_sphere(num_ins)\n",
    "    # Remove from the beginning of the list so that gradually\n",
    "    # all initial points get removed\n",
    "    return np.concatenate((pt_list[num_del::, :] , new_points), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the dynamic network analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.spatial.distance import squareform\n",
    "sys.path.append('../shared_scripts/')\n",
    "import graph_fns as gf\n",
    "import persistence_fns as pf\n",
    "import sliding_window_fns as sw\n",
    "from ripser import ripser, plot_dgms\n",
    "from sklearn import manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change edge weights to constants\n",
    "#edge_wts = np.ones((len(edge_wts),edge_wts[0].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def inverse_x_phi_fn(x):\n",
    "    1.0/(a+0.1)\n",
    "    return np.array([1/(a + 0.1) for a in x])\n",
    "\n",
    "def linear_phi_fn(x):\n",
    "    return 10-x\n",
    "\n",
    "def identity_phi_fn(x):\n",
    "    return x\n",
    "\n",
    "def apply_pipeline(node_wts, edge_wts, d, tau):\n",
    "    \n",
    "    # apply phi functions, and scale the weights\n",
    "    phi_node_wts, phi_edge_wts = gf.weight_fn(node_wts, edge_wts, lamda=1, phi=identity_phi_fn)\n",
    "\n",
    "    # constrcut the filtrations / simplicial complexes according to our construction\n",
    "    filtration_matrix = list(map(lambda n, e: pf.get_filtration(n, e), phi_node_wts, phi_edge_wts))\n",
    "    # summarize these filtrations using H_0 barcodes\n",
    "    barcodes = list(map(pf.get_rips_complex, filtration_matrix))\n",
    "\n",
    "    # get bottleneck distance between all the H0 diagrams;\n",
    "    bn_dist_matrix = pf.get_bottleneck_dist_matrix(barcodes)\n",
    "    \n",
    "    # construct a sliding window embedding\n",
    "    sw_vecs_indices = sw.sliding_window(range(len(barcodes)), d=d, tau=tau)\n",
    "    sw_dist_matrix = sw.sw_distance_matrix(sw_vecs_indices, bn_dist_matrix)\n",
    "\n",
    "    # get H1 from the sliding window distance matrix\n",
    "    PDs = ripser(sw_dist_matrix, distance_matrix=True, maxdim=1, coeff=2)['dgms']\n",
    "    \n",
    "    return PDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maximum_persistence(PD):\n",
    "    num_dim = len(PD)\n",
    "\n",
    "    #has to be a 2D array\n",
    "    def max_pers(array): \n",
    "        if len(array) == 0:\n",
    "            return 0\n",
    "        diff = array[:,1] - array[:,0]\n",
    "        return max(diff)\n",
    "\n",
    "    return list(map(max_pers,PD))\n",
    "\n",
    "# gets the difference between the persistences of the first and second top features\n",
    "def get_top_diff_persistence(PD):\n",
    "    num_dim = len(PD)\n",
    "    \n",
    "    def get_diff(array):\n",
    "        if len(array) == 0:\n",
    "            return 0\n",
    "        diff = array[:,1] - array[:,0]\n",
    "        sorted_diff = sorted(diff,reverse = True)\n",
    "        if len(sorted_diff) == 1:\n",
    "            return sorted_diff[0]\n",
    "        else:\n",
    "            return sorted_diff[0] - sorted_diff[1]\n",
    "        \n",
    "    return(list(map(get_diff,PD)))\n",
    "        \n",
    "def get_num_features(PD):\n",
    "    return(list(map(len,PD)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup Dynamic Network\n",
    "ts = np.arange(200)\n",
    "T = 60 # Period \n",
    "change_param = 5\n",
    "obsfn = lambda t, p: periodic_northsouth_modulated(t,p,T)\n",
    "edge_wtsfn = lambda hull_obj: get_edge_wts(hull_obj, alpha = 1.0)\n",
    "(node_wts,edge_wts, allpoints) = create_dynamic_network(ts, obsfn=obsfn, edge_wtsfn=edge_wtsfn, change_param=change_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a video of the evolving sphere\n",
    "# Step 0: Compute persistence diagrams\n",
    "# apply phi functions, and scale the weights\n",
    "phi_node_wts, phi_edge_wts = gf.weight_fn(node_wts, edge_wts, lamda=1, phi=identity_phi_fn)\n",
    "\n",
    "# constrcut the filtrations / simplicial complexes according to our construction\n",
    "filtration_matrix = list(map(lambda n, e: pf.get_filtration(n, e), phi_node_wts, phi_edge_wts))\n",
    "# summarize these filtrations using H_0 barcodes\n",
    "barcodes = list(map(pf.get_rips_complex, filtration_matrix))\n",
    "\n",
    "# Step 1: Figure out dynamic range of observation function\n",
    "xs = []\n",
    "for nw in node_wts:\n",
    "    xs += nw.tolist()\n",
    "xs = np.array(xs)\n",
    "nmin = np.min(xs)\n",
    "nmax = np.max(xs)\n",
    "plt.figure(figsize=(18, 6))\n",
    "for i, (pts, nw, dgm) in enumerate(zip(allpoints, phi_node_wts, barcodes)):\n",
    "    plt.clf()\n",
    "    ax = plt.gcf().add_subplot(121, projection='3d')\n",
    "    pts = np.concatenate((pts, np.zeros((2, 3))), 0)\n",
    "    nw = np.concatenate((nw, np.array([nmin, nmax])))\n",
    "    p = ax.scatter(pts[:, 0], pts[:, 1], pts[:, 2], c=nw, s=100, cmap=plt.get_cmap(\"magma\"))\n",
    "    plt.colorbar(p)\n",
    "    hull = sp.ConvexHull(pts)\n",
    "    for simplex in hull.simplices:\n",
    "         ax.plot(pts[simplex, 0], pts[simplex, 1], pts[simplex, 2], 'k-')\n",
    "    plt.title(\"Timestep %i\"%i)\n",
    "    plt.subplot(122)\n",
    "    plot_dgms(dgm, labels=['H0'])\n",
    "    plt.xlim([4, 12])\n",
    "    plt.ylim([4, 12])\n",
    "    plt.title(\"%i Nodes, %i Dots\"%(nw.shape[0]-2, dgm.shape[0]))\n",
    "    plt.savefig(\"%i.png\"%i, bbox_inches='tight')\n",
    "\n",
    "PDs = apply_pipeline(node_wts, edge_wts, d = 60, tau = 1) # get the PDs\n",
    "plt.figure()\n",
    "plot_dgms(PDs, show=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_test_values = range(1,10)\n",
    "dim_test_values = range(2,10)\n",
    "\n",
    "mpers_results = np.zeros((len(tau_test_values),len(dim_test_values)))\n",
    "top_diff_results = np.zeros((len(tau_test_values),len(dim_test_values)))\n",
    "\n",
    "for tau in tau_test_values:\n",
    "    for d in dim_test_values:\n",
    "        print(tau,d)\n",
    "        \n",
    "        PDs = apply_pipeline(node_wts,edge_wts, d = d, tau = tau) # get the PDs\n",
    "        res = (get_maximum_persistence(PDs)[1],get_top_diff_persistence(PDs)[1], get_num_features(PDs)[1])\n",
    "        print(res)\n",
    "        \n",
    "        mpers_results[tau - min(tau_test_values),d - min(dim_test_values)] = res[0]\n",
    "        top_diff_results[tau - min(tau_test_values),d - min(dim_test_values)] = res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "plt.gcf().clear()\n",
    "fig, axs = plt.subplots(2,1, figsize = (7,7))\n",
    "\n",
    "im1 = axs[0].imshow(mpers_results)\n",
    "\n",
    "axs[0].set_xlabel('dimension')\n",
    "axs[0].set_xticks(np.arange(len(dim_test_values)))\n",
    "axs[0].set_xticklabels(labels = list(dim_test_values))\n",
    "\n",
    "axs[0].set_ylabel('tau')\n",
    "axs[0].set_yticks(np.arange(len(tau_test_values)))\n",
    "axs[0].set_yticklabels(labels = list(tau_test_values))\n",
    "\n",
    "axs[0].set_title('Max Pers.')\n",
    "\n",
    "divider1 = make_axes_locatable(axs[0])\n",
    "cax1 = divider1.append_axes('right', size='5%', pad=0.1)\n",
    "fig.colorbar(im1,cax1,orientation = 'vertical')\n",
    "\n",
    "### Do the other plot ###\n",
    "\n",
    "im2 = axs[1].imshow(np.divide(top_diff_results,mpers_results),cmap = plt.cm.magma)\n",
    "\n",
    "axs[1].set_xlabel('dimension')\n",
    "axs[1].set_xticks(np.arange(len(dim_test_values)))\n",
    "axs[1].set_xticklabels(labels = list(dim_test_values))\n",
    "\n",
    "\n",
    "axs[1].set_ylabel('tau')\n",
    "axs[1].set_yticks(np.arange(len(tau_test_values)))\n",
    "axs[1].set_yticklabels(labels = list(tau_test_values))\n",
    "axs[1].set_title('Ratio of Pers. Diff. vs. Max Pers.')\n",
    "\n",
    "divider2 = make_axes_locatable(axs[1])\n",
    "cax2 = divider2.append_axes('right', size='5%', pad=0.1)\n",
    "fig.colorbar(im2,cax2)\n",
    "\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "fig.suptitle('Max Persistence vs. tau and d', fontsize = 15)\n",
    "plt.savefig('sphere_Maxpers_and_ratio_change=%i_remove_old_pts' %change_param)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
